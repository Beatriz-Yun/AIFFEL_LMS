{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "[FD-15]numpy로MLP구현.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyM2lFOAE+yhkQUEhqheps/4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Beatriz-Yun/AIFFEL_LMS/blob/main/Fundamental/%5BFD_15%5Dnumpy%EB%A1%9CMLP%EA%B5%AC%ED%98%84.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tWzMrQA83Jvj"
      },
      "source": [
        "딥러닝 프레임워크 tensorflow를 사용하여 MNIST 이미지 분류기 구현"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_gMekeCy1b8Y",
        "outputId": "bc6c60d2-e707-41a5-97c0-f5a96e878064"
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# MNIST 데이터를 로드. 다운로드하지 않았다면 다운로드까지 자동으로 진행됩니다. \n",
        "mnist = keras.datasets.mnist\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()   \n",
        "\n",
        "# 모델에 맞게 데이터 가공\n",
        "x_train_norm, x_test_norm = x_train / 255.0, x_test / 255.0\n",
        "x_train_reshaped = x_train_norm.reshape(-1, x_train_norm.shape[1]*x_train_norm.shape[2])\n",
        "x_test_reshaped = x_test_norm.reshape(-1, x_test_norm.shape[1]*x_test_norm.shape[2])\n",
        "\n",
        "# 딥러닝 모델 구성 - 2 Layer Perceptron\n",
        "model=keras.models.Sequential()\n",
        "model.add(keras.layers.Dense(50, activation='sigmoid', input_shape=(784,)))  # 입력층 d=784, 은닉층 레이어 H=50\n",
        "model.add(keras.layers.Dense(10, activation='softmax'))   # 출력층 레이어 K=10\n",
        "model.summary()\n",
        "\n",
        "# 모델 구성과 학습\n",
        "model.compile(optimizer='adam',\n",
        "             loss='sparse_categorical_crossentropy',\n",
        "             metrics=['accuracy'])\n",
        "model.fit(x_train_reshaped, y_train, epochs=10)\n",
        "\n",
        "# 모델 테스트 결과\n",
        "test_loss, test_accuracy = model.evaluate(x_test_reshaped,y_test, verbose=2)\n",
        "print(\"test_loss: {} \".format(test_loss))\n",
        "print(\"test_accuracy: {}\".format(test_accuracy))"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_2 (Dense)              (None, 50)                39250     \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 10)                510       \n",
            "=================================================================\n",
            "Total params: 39,760\n",
            "Trainable params: 39,760\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/10\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.4987 - accuracy: 0.8829\n",
            "Epoch 2/10\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.2293 - accuracy: 0.9357\n",
            "Epoch 3/10\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.1797 - accuracy: 0.9488\n",
            "Epoch 4/10\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.1511 - accuracy: 0.9562\n",
            "Epoch 5/10\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.1311 - accuracy: 0.9624\n",
            "Epoch 6/10\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.1162 - accuracy: 0.9664\n",
            "Epoch 7/10\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.1042 - accuracy: 0.9704\n",
            "Epoch 8/10\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0941 - accuracy: 0.9734\n",
            "Epoch 9/10\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0847 - accuracy: 0.9766\n",
            "Epoch 10/10\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0778 - accuracy: 0.9784\n",
            "313/313 - 0s - loss: 0.1117 - accuracy: 0.9675\n",
            "test_loss: 0.11170224845409393 \n",
            "test_accuracy: 0.9674999713897705\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8NRWeBji3Y-y"
      },
      "source": [
        "다층 퍼셉트론(MLP)는 Fully-Connected Neural Network이다.\n",
        "- 인접한 층에 위치한 노드들 간의 연결만 존재한다\n",
        "- Fully-Connected layer = Dense layer = Affine layer\n",
        "\n",
        "<br>\n",
        "\n",
        "---\n",
        "\n",
        "<br>\n",
        "\n",
        "## Numpy로 MLP기반 MNIST분류모델 구현\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hl83vgGl5bPD",
        "outputId": "a515cec9-70e9-440a-eb50-a5bdd10055ab"
      },
      "source": [
        "# 입력층 데이터 크기(shape)\n",
        "print(x_train_reshaped.shape)\n",
        "\n",
        "# 테스트를 위해 x_train_reshaped의 앞 5개의 데이터를 가져온다.\n",
        "X = x_train_reshaped[:5]\n",
        "print(X.shape)"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(60000, 784)\n",
            "(5, 784)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9Rq5ItuU6JJz",
        "outputId": "9447e983-ca9a-4817-a405-a8363d51ee8f"
      },
      "source": [
        "weight_init_std = 0.1\n",
        "input_size = 784\n",
        "hidden_size=50\n",
        "\n",
        "# 인접 레이어간 관계를 나타내는 파라미터 W를 생성하고 random 초기화\n",
        "W1 = weight_init_std * np.random.randn(input_size, hidden_size)  \n",
        "# 바이어스 파라미터 b를 생성하고 Zero로 초기화\n",
        "b1 = np.zeros(hidden_size)\n",
        "\n",
        "a1 = np.dot(X, W1) + b1   # 은닉층 출력\n",
        "\n",
        "print(W1)\n",
        "print(W1.shape)\n",
        "print(b1.shape)\n",
        "print(a1.shape)"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[-0.11636312 -0.04022246 -0.05951997 ...  0.23867343 -0.02823106\n",
            "   0.05809429]\n",
            " [-0.14705484  0.01214889 -0.08747341 ... -0.05886045  0.11783454\n",
            "   0.0089944 ]\n",
            " [-0.11025757 -0.17292251 -0.0325627  ...  0.02173628  0.09796562\n",
            "  -0.03272894]\n",
            " ...\n",
            " [-0.16072537  0.0525449  -0.022696   ... -0.02900932 -0.00803232\n",
            "  -0.08782937]\n",
            " [ 0.0309641   0.20698941  0.05298593 ...  0.00463074 -0.05547726\n",
            "  -0.04411454]\n",
            " [ 0.031398    0.04238187  0.091853   ... -0.02099508 -0.27199017\n",
            "   0.07992111]]\n",
            "(784, 50)\n",
            "(50,)\n",
            "(5, 50)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vYWr1dfB6aWX",
        "outputId": "b71a1fc2-31f9-4f15-e747-233d24301671"
      },
      "source": [
        "# 첫 번째 데이터의 은닉층 출력 확인\n",
        "a1[0]"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([-1.3661741 , -0.1220015 ,  0.30350907,  1.61420187, -0.26306848,\n",
              "        0.50776336,  0.7591472 ,  1.73163178,  0.09342599,  1.36813594,\n",
              "        0.59494302, -0.91727598, -1.05290807, -0.85776067, -1.13667362,\n",
              "       -0.21099751,  1.57536648,  0.75330476, -0.44202524, -0.0184326 ,\n",
              "       -0.23032552, -0.379493  ,  1.05515265, -0.38281998,  0.00393502,\n",
              "       -1.6174888 , -1.01880626, -1.17474624, -0.19767829, -1.59074383,\n",
              "        0.3360553 ,  0.61044617, -0.78347439, -0.60019195,  1.3548584 ,\n",
              "       -0.816523  , -0.36184818,  0.46451647, -0.25170335,  0.27087545,\n",
              "        2.270746  , -0.97772093,  0.61803946,  1.50306793, -1.57928601,\n",
              "       -1.40957123,  1.29250076, -0.90952229,  0.13857081, -0.68544587])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tCZA2H0u7Cyd"
      },
      "source": [
        "활성화 함수 (Activation Function)\n",
        "- 은닉층: sigmoid\n",
        "- 출력층: softmax\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NBjAHhNm7Fkf",
        "outputId": "037d4e05-3690-45e1-b043-d24c107bbd56"
      },
      "source": [
        "# sigmoid함수\n",
        "def sigmoid(x):\n",
        "    return 1 / (1 + np.exp(-x))  \n",
        "\n",
        "\n",
        "z1 = sigmoid(a1)\n",
        "print(z1[0])        # sigmoid의 출력은 항상 0에서 1사이"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0.20323868 0.4695374  0.57530011 0.83399394 0.43460956 0.62428201\n",
            " 0.68116855 0.84962102 0.52333952 0.79707882 0.6444985  0.28551326\n",
            " 0.25866706 0.29780742 0.24293161 0.44744545 0.8285473  0.67989836\n",
            " 0.3912585  0.49539198 0.44267183 0.40624919 0.74176312 0.40544693\n",
            " 0.50098375 0.16555149 0.26525999 0.23599815 0.45074073 0.16927927\n",
            " 0.58323199 0.64804257 0.31357156 0.35429978 0.79492278 0.30650223\n",
            " 0.41051225 0.61408506 0.43740429 0.56730781 0.90642508 0.27334424\n",
            " 0.64977252 0.8180316  0.17089662 0.19630169 0.78457017 0.2870976\n",
            " 0.53458737 0.33504693]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OyfX-W_K7XUl"
      },
      "source": [
        "# MLP의 단일 레이어\n",
        "def affine_layer_forward(X, W, b):\n",
        "    y = np.dot(X, W) + b\n",
        "    cache = (X, W, b)\n",
        "    return y, cache"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ObBXuBuE7_90",
        "outputId": "d49c16d9-60da-47b8-d379-5f2c9c615007"
      },
      "source": [
        "input_size = 784\n",
        "hidden_size = 50\n",
        "output_size = 10\n",
        "\n",
        "W1 = weight_init_std * np.random.randn(input_size, hidden_size)\n",
        "b1 = np.zeros(hidden_size)\n",
        "W2 = weight_init_std * np.random.randn(hidden_size, output_size)\n",
        "b2 = np.zeros(output_size)\n",
        "\n",
        "a1, cache1 = affine_layer_forward(X, W1, b1)\n",
        "z1 = sigmoid(a1)\n",
        "a2, cache2 = affine_layer_forward(z1, W2, b2)    # z1이 다시 두번째 레이어의 입력이 됩니다. \n",
        "\n",
        "print(a2[0])  # 최종 출력이 output_size만큼의 벡터가 되었습니다."
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[ 0.58518673 -0.27943011 -0.33376812 -0.35527845 -0.42551617 -0.41868551\n",
            "  0.37707514 -0.20326282  0.03552438  0.38494289]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TNAEc-Da8f67"
      },
      "source": [
        "def softmax(x):\n",
        "    if x.ndim == 2:\n",
        "        x = x.T\n",
        "        x = x - np.max(x, axis=0)\n",
        "        y = np.exp(x) / np.sum(np.exp(x), axis=0)\n",
        "        return y.T \n",
        "\n",
        "    x = x - np.max(x) # 오버플로 대책\n",
        "    return np.exp(x) / np.sum(np.exp(x))"
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Io-Rq5Hm9SrK",
        "outputId": "e9966d02-acb0-488f-b259-3525b824cf2f"
      },
      "source": [
        "y_hat = softmax(a2)\n",
        "y_hat[0]  # 10개의 숫자 중 하나일 확률이 되었습니다."
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.17846445, 0.07517153, 0.07119585, 0.06968076, 0.06495447,\n",
              "       0.06539967, 0.14493391, 0.08112084, 0.1029998 , 0.14607871])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3nOt0si_94d9"
      },
      "source": [
        "손실함수 (Loss function)\n",
        "- 평균제곱오차(MSE)\n",
        "- Cross Entropy는 두 확률분포 사이의 유사도가 클수록 작아지는 값이다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JMfItRpaA152",
        "outputId": "80c9c4f2-c885-4822-9dc4-b7978341d7fa"
      },
      "source": [
        "# 정답 라벨을 One-hot 인코딩하는 함수\n",
        "def _change_ont_hot_label(X, num_category):\n",
        "    T = np.zeros((X.size, num_category))\n",
        "    for idx, row in enumerate(T):\n",
        "        row[X[idx]] = 1\n",
        "        \n",
        "    return T\n",
        "\n",
        "Y_digit = y_train[:5]\n",
        "t = _change_ont_hot_label(Y_digit, 10)\n",
        "t     # 정답 라벨의 One-hot 인코딩"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0., 0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
              "       [1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
              "       [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 1.]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kqIuePRqUoow",
        "outputId": "2d1b45b0-eb96-4ecb-dfdf-6b025400ea72"
      },
      "source": [
        "print(y_hat[0])\n",
        "print(t[0])"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0.17846445 0.07517153 0.07119585 0.06968076 0.06495447 0.06539967\n",
            " 0.14493391 0.08112084 0.1029998  0.14607871]\n",
            "[0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XqEnRRWUULio",
        "outputId": "7e322bd6-e33a-4971-fc26-8347f39bfca4"
      },
      "source": [
        "def cross_entropy_error(y, t):\n",
        "    if y.ndim == 1:\n",
        "        t = t.reshape(1, t.size)\n",
        "        y = y.reshape(1, y.size)\n",
        "        \n",
        "    # 훈련 데이터가 원-핫 벡터라면 정답 레이블의 인덱스로 반환\n",
        "    if t.size == y.size:\n",
        "        t = t.argmax(axis=1)\n",
        "             \n",
        "    batch_size = y.shape[0]\n",
        "    return -np.sum(np.log(y[np.arange(batch_size), t])) / batch_size\n",
        "\n",
        "Loss = cross_entropy_error(y_hat, t)\n",
        "Loss"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2.392838089292192"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DMqYxqEHUxco"
      },
      "source": [
        "가중치 초기화"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yWBrv_LvUlw9",
        "outputId": "9c46a3fa-3163-4eb5-d5b6-5337d9b9a89a"
      },
      "source": [
        "batch_num = y_hat.shape[0]\n",
        "dy = (y_hat - t) / batch_num\n",
        "dy    # softmax값의 출력으로 Loss를 미분한 값"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 0.03569289,  0.01503431,  0.01423917,  0.01393615,  0.01299089,\n",
              "        -0.18692007,  0.02898678,  0.01622417,  0.02059996,  0.02921574],\n",
              "       [-0.16659877,  0.01532682,  0.01549666,  0.01139185,  0.01413001,\n",
              "         0.0192093 ,  0.03141199,  0.01376885,  0.02033049,  0.02553281],\n",
              "       [ 0.03218097,  0.01585157,  0.02003275,  0.01093483, -0.18663656,\n",
              "         0.01935213,  0.02950513,  0.01438821,  0.02084399,  0.02354696],\n",
              "       [ 0.04017134, -0.18340089,  0.01913911,  0.01113369,  0.01293761,\n",
              "         0.01374439,  0.02559016,  0.0146642 ,  0.01843512,  0.02758528],\n",
              "       [ 0.03453175,  0.01958347,  0.01455834,  0.01297014,  0.01535373,\n",
              "         0.01765771,  0.03000395,  0.01493805,  0.01937491, -0.17897205]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y5MMi6GEU2do",
        "outputId": "00ba6256-8693-44bd-9986-8e6a47f88a9b"
      },
      "source": [
        "dW2 = np.dot(z1.T, dy)    \n",
        "dW2"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[-0.05925423, -0.10658139,  0.04989276,  0.0358963 , -0.03599147,\n",
              "        -0.06417427,  0.08688513,  0.04410069,  0.05938513, -0.01015865],\n",
              "       [-0.04755767, -0.07622556,  0.05893113,  0.04378137, -0.05827507,\n",
              "        -0.11626017,  0.104992  ,  0.05334959,  0.07174162, -0.03447724],\n",
              "       [-0.02164818, -0.1015745 ,  0.06220242,  0.04510614, -0.08251027,\n",
              "        -0.09614246,  0.10834769,  0.05528409,  0.07423694, -0.04330188],\n",
              "       [ 0.00936355, -0.02059717,  0.02933084,  0.02029735, -0.08911892,\n",
              "         0.00714405,  0.05017592,  0.02502953,  0.03411506, -0.06574021],\n",
              "       [-0.01073372, -0.0028712 ,  0.02576565,  0.01882166, -0.05991603,\n",
              "        -0.02396266,  0.04603251,  0.02292808,  0.03122595, -0.04729022],\n",
              "       [-0.00233782, -0.10483719,  0.04143584,  0.0302141 , -0.02200738,\n",
              "        -0.06725747,  0.07153971,  0.03703768,  0.04912369, -0.03291116],\n",
              "       [-0.01965606, -0.03695179,  0.02582596,  0.01876202, -0.03877329,\n",
              "        -0.06139542,  0.04507952,  0.02302913,  0.0310672 ,  0.01301274],\n",
              "       [ 0.00126799, -0.04379549,  0.04459807,  0.03302165, -0.07343148,\n",
              "        -0.09133585,  0.07879869,  0.04025717,  0.05401702, -0.04339778],\n",
              "       [-0.00568964, -0.0838982 ,  0.03279524,  0.02252648, -0.04660944,\n",
              "         0.00638537,  0.05500286,  0.02793039,  0.03754008, -0.04598314],\n",
              "       [ 0.00081766, -0.06437124,  0.04437748,  0.03268075, -0.06050425,\n",
              "        -0.09119243,  0.07773895,  0.03993024,  0.05339569, -0.03287283],\n",
              "       [-0.00992507, -0.09583437,  0.05160307,  0.0379245 , -0.05368754,\n",
              "        -0.1194059 ,  0.08993097,  0.04642646,  0.06195279, -0.00898491],\n",
              "       [-0.05319328, -0.04924195,  0.05288599,  0.04053113, -0.0269758 ,\n",
              "        -0.11047096,  0.09680205,  0.04897716,  0.06573915, -0.0650535 ],\n",
              "       [ 0.02973777, -0.06161595,  0.03856609,  0.02823858, -0.06135061,\n",
              "        -0.07238164,  0.06673343,  0.03454391,  0.04592862, -0.04840019],\n",
              "       [-0.05774571, -0.02743498,  0.03592273,  0.02599521, -0.0461033 ,\n",
              "         0.01216868,  0.06464931,  0.03167701,  0.04332768, -0.08245664],\n",
              "       [-0.0422724 , -0.09605381,  0.05153421,  0.0374421 , -0.04137759,\n",
              "        -0.05310621,  0.09042761,  0.04582424,  0.06157852, -0.05399667],\n",
              "       [ 0.00033783, -0.08128684,  0.03734972,  0.02690482, -0.03890635,\n",
              "        -0.04295692,  0.06431981,  0.03302776,  0.04405469, -0.04284452],\n",
              "       [-0.00719699, -0.080392  ,  0.0313142 ,  0.02094177, -0.06296203,\n",
              "         0.00102804,  0.05151776,  0.02617309,  0.03539294, -0.01581678],\n",
              "       [ 0.00798368, -0.09529413,  0.04222562,  0.02969444, -0.0616691 ,\n",
              "        -0.02521515,  0.07155673,  0.0366399 ,  0.04901761, -0.05493962],\n",
              "       [ 0.01560749, -0.07508789,  0.04148776,  0.02834668, -0.11096618,\n",
              "        -0.04700485,  0.06882134,  0.03528133,  0.04764631, -0.00413199],\n",
              "       [-0.04179734, -0.07655858,  0.05240859,  0.03730995, -0.08900079,\n",
              "        -0.06957317,  0.09082505,  0.04591962,  0.06222384, -0.01175717],\n",
              "       [ 0.05768002, -0.07873621,  0.03634628,  0.02700717, -0.03255631,\n",
              "        -0.04639215,  0.06291298,  0.03288349,  0.04307834, -0.10222363],\n",
              "       [-0.05360608, -0.0608692 ,  0.04665525,  0.03404951, -0.04381337,\n",
              "        -0.01967171,  0.08320244,  0.04151811,  0.05618557, -0.08365051],\n",
              "       [-0.04873801, -0.01586514,  0.04587365,  0.03549402, -0.0431426 ,\n",
              "        -0.1320054 ,  0.08464593,  0.04283236,  0.0577156 , -0.0268104 ],\n",
              "       [ 0.02530163, -0.09386168,  0.04079913,  0.02690072, -0.11670951,\n",
              "        -0.00254929,  0.06598566,  0.03374531,  0.04560073, -0.02521271],\n",
              "       [-0.05707556, -0.05102254,  0.05156908,  0.03738684, -0.07624387,\n",
              "        -0.04383254,  0.09153322,  0.04569628,  0.06210624, -0.06011714],\n",
              "       [-0.03346875, -0.03162441,  0.04698274,  0.03633024, -0.03033236,\n",
              "        -0.10437146,  0.08644221,  0.04379536,  0.05869388, -0.07244744],\n",
              "       [ 0.04460879, -0.10117061,  0.04382265,  0.03251072, -0.03951538,\n",
              "        -0.11336416,  0.07543569,  0.03975035,  0.05223732, -0.03431536],\n",
              "       [ 0.00692037, -0.04821807,  0.03549705,  0.0242194 , -0.09521365,\n",
              "         0.01691353,  0.05989602,  0.02999724,  0.04077397, -0.07078586],\n",
              "       [ 0.00559475, -0.03328636,  0.04871057,  0.03489935, -0.12431928,\n",
              "        -0.06582993,  0.08465143,  0.04282007,  0.05800965, -0.05125025],\n",
              "       [-0.02655203, -0.06272002,  0.03563002,  0.02545617, -0.0408427 ,\n",
              "        -0.0107574 ,  0.0621055 ,  0.03122839,  0.04214026, -0.05568821],\n",
              "       [ 0.02935148, -0.05948972,  0.03545313,  0.02467601, -0.09650695,\n",
              "        -0.06993866,  0.05902856,  0.03061725,  0.04109835,  0.00571054],\n",
              "       [-0.02127542, -0.07782296,  0.05723945,  0.04161498, -0.08751827,\n",
              "        -0.09680328,  0.10009347,  0.05096672,  0.06860058, -0.03509528],\n",
              "       [ 0.05619633, -0.10866191,  0.04541646,  0.03240061, -0.07122256,\n",
              "        -0.06632183,  0.07632119,  0.0399197 ,  0.0527525 , -0.0568005 ],\n",
              "       [-0.032823  , -0.07329888,  0.03298166,  0.02356896, -0.02780156,\n",
              "        -0.0386127 ,  0.05704031,  0.02900339,  0.03902365, -0.00908183],\n",
              "       [ 0.05209628, -0.09416652,  0.03177862,  0.02000638, -0.11008917,\n",
              "         0.01598774,  0.04902624,  0.02541975,  0.03415987, -0.0242192 ],\n",
              "       [ 0.02585635, -0.0960527 ,  0.02514658,  0.01763421, -0.0193871 ,\n",
              "        -0.05183602,  0.04101435,  0.02191857,  0.0286842 ,  0.00702156],\n",
              "       [-0.05358583, -0.04571541,  0.03510228,  0.02446622, -0.06071549,\n",
              "         0.00638171,  0.0611222 ,  0.03015565,  0.04134811, -0.03855945],\n",
              "       [-0.01635422, -0.03077848,  0.0349037 ,  0.02620299, -0.04035734,\n",
              "        -0.05947347,  0.06280121,  0.0317969 ,  0.04273098, -0.05147226],\n",
              "       [ 0.01976326, -0.0643939 ,  0.02028429,  0.01341493, -0.04394604,\n",
              "        -0.00232806,  0.03241639,  0.0168414 ,  0.02246748, -0.01451976],\n",
              "       [-0.00980123, -0.07018159,  0.03852341,  0.02740678, -0.06494114,\n",
              "        -0.06862311,  0.06589836,  0.03379683,  0.04545261,  0.00246907],\n",
              "       [-0.01748311, -0.02877181,  0.02689856,  0.0185316 , -0.07742498,\n",
              "        -0.0419218 ,  0.04560425,  0.02301325,  0.03150285,  0.02005119],\n",
              "       [-0.01314258, -0.02638167,  0.02623808,  0.01928962, -0.04552248,\n",
              "        -0.06842339,  0.04619324,  0.02359836,  0.03182677,  0.00632403],\n",
              "       [-0.03505113, -0.06280021,  0.06425972,  0.04690419, -0.10357244,\n",
              "        -0.07989021,  0.11366363,  0.05728033,  0.07742561, -0.07821948],\n",
              "       [-0.03288874, -0.08453593,  0.05916329,  0.04435633, -0.04577307,\n",
              "        -0.12596784,  0.10557218,  0.05395258,  0.07218213, -0.04606093],\n",
              "       [-0.05992045, -0.04730658,  0.04845957,  0.03329238, -0.12281606,\n",
              "        -0.01297933,  0.08332697,  0.04122381,  0.05677486, -0.02005519],\n",
              "       [ 0.0342719 , -0.05710739,  0.03791488,  0.02793743, -0.0624996 ,\n",
              "        -0.08496354,  0.06571579,  0.03414529,  0.0453358 , -0.04075056],\n",
              "       [-0.00841176, -0.05105904,  0.01978818,  0.01424622, -0.01452261,\n",
              "        -0.03908621,  0.03388561,  0.01754281,  0.02338172,  0.00423508],\n",
              "       [-0.02803941, -0.07085905,  0.02522841,  0.01753932, -0.02189257,\n",
              "        -0.02447456,  0.0426445 ,  0.02175692,  0.02929722,  0.00879922],\n",
              "       [-0.07881554, -0.00787126,  0.03839674,  0.02923336, -0.02953765,\n",
              "        -0.04974041,  0.07153403,  0.03527677,  0.04810518, -0.05658123],\n",
              "       [ 0.02685852, -0.04211798,  0.02778137,  0.02023516, -0.04167964,\n",
              "        -0.00774226,  0.04835037,  0.02467843,  0.03282793, -0.0891919 ]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NpJdJNmcU_HX"
      },
      "source": [
        "dW2 = np.dot(z1.T, dy)\n",
        "db2 = np.sum(dy, axis=0)"
      ],
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FomfdvrLVBNr"
      },
      "source": [
        "def sigmoid_grad(x):\n",
        "    return (1.0 - sigmoid(x)) * sigmoid(x)"
      ],
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Py2m-YYfVCjY"
      },
      "source": [
        "learning_rate = 0.1\n",
        "\n",
        "def update_params(W1, b1, W2, b2, dW1, db1, dW2, db2, learning_rate):\n",
        "    W1 = W1 - learning_rate*dW1\n",
        "    b1 = b1 - learning_rate*db1\n",
        "    W2 = W2 - learning_rate*dW2\n",
        "    b2 = b2 - learning_rate*db2\n",
        "    return W1, b1, W2, b2"
      ],
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "renrkVriVEa4"
      },
      "source": [
        "learning_rate = 0.1\n",
        "\n",
        "def update_params(W1, b1, W2, b2, dW1, db1, dW2, db2, learning_rate):\n",
        "    W1 = W1 - learning_rate*dW1\n",
        "    b1 = b1 - learning_rate*db1\n",
        "    W2 = W2 - learning_rate*dW2\n",
        "    b2 = b2 - learning_rate*db2\n",
        "    return W1, b1, W2, b2"
      ],
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U-M_63s_VGu4"
      },
      "source": [
        "def affine_layer_backward(dy, cache):\n",
        "    X, W, b = cache\n",
        "    dX = np.dot(dy, W.T)\n",
        "    dW = np.dot(X.T, dy)\n",
        "    db = np.sum(dy, axis=0)\n",
        "    return dX, dW, db"
      ],
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SUcid9FxVIGw",
        "outputId": "833f4747-ef0d-4dcb-ac2c-7bdc88dff1a6"
      },
      "source": [
        "# 파라미터 초기화\n",
        "W1 = weight_init_std * np.random.randn(input_size, hidden_size)\n",
        "b1 = np.zeros(hidden_size)\n",
        "W2 = weight_init_std * np.random.randn(hidden_size, output_size)\n",
        "b2 = np.zeros(output_size)\n",
        "\n",
        "# Forward Propagation\n",
        "a1, cache1 = affine_layer_forward(X, W1, b1)\n",
        "z1 = sigmoid(a1)\n",
        "a2, cache2 = affine_layer_forward(z1, W2, b2)\n",
        "\n",
        "# 추론과 오차(Loss) 계산\n",
        "y_hat = softmax(a2)\n",
        "t = _change_ont_hot_label(Y_digit, 10)   # 정답 One-hot 인코딩\n",
        "Loss = cross_entropy_error(y_hat, t)\n",
        "\n",
        "print(y_hat)\n",
        "print(t)\n",
        "print('Loss: ', Loss)\n",
        "        \n",
        "dy = (y_hat - t) / X.shape[0]\n",
        "dz1, dW2, db2 = affine_layer_backward(dy, cache2)\n",
        "da1 = sigmoid_grad(a1) * dz1\n",
        "dX, dW1, db1 = affine_layer_backward(da1, cache1)\n",
        "\n",
        "# 경사하강법을 통한 파라미터 업데이트    \n",
        "learning_rate = 0.1\n",
        "W1, b1, W2, b2 = update_params(W1, b1, W2, b2, dW1, db1, dW2, db2, learning_rate)"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[0.03934916 0.1164047  0.05213654 0.07591309 0.0661011  0.11374123\n",
            "  0.09111826 0.20093323 0.15755609 0.0867466 ]\n",
            " [0.0276103  0.12279003 0.05151038 0.08862549 0.07120887 0.09965035\n",
            "  0.09530896 0.21058005 0.14464655 0.08806903]\n",
            " [0.03857162 0.09287727 0.05324716 0.07137478 0.06206637 0.08635399\n",
            "  0.11419342 0.22325989 0.14751292 0.11054258]\n",
            " [0.0289163  0.11337894 0.05493461 0.07564991 0.05735017 0.09350559\n",
            "  0.1041277  0.19508917 0.18302894 0.09401868]\n",
            " [0.0295081  0.10936981 0.05406895 0.08556347 0.05789676 0.0822325\n",
            "  0.09668114 0.26617401 0.13773234 0.08077291]]\n",
            "[[0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
            " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]]\n",
            "Loss:  2.6472159715841292\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gRCG45dnVM8I"
      },
      "source": [
        "W1 = weight_init_std * np.random.randn(input_size, hidden_size)\n",
        "b1 = np.zeros(hidden_size)\n",
        "W2 = weight_init_std * np.random.randn(hidden_size, output_size)\n",
        "b2 = np.zeros(output_size)\n",
        "\n",
        "def train_step(X, Y, W1, b1, W2, b2, learning_rate=0.1, verbose=False):\n",
        "    a1, cache1 = affine_layer_forward(X, W1, b1)\n",
        "    z1 = sigmoid(a1)\n",
        "    a2, cache2 = affine_layer_forward(z1, W2, b2)\n",
        "    y_hat = softmax(a2)\n",
        "    t = _change_ont_hot_label(Y, 10)\n",
        "    Loss = cross_entropy_error(y_hat, t)\n",
        "\n",
        "    if verbose:\n",
        "        print('---------')\n",
        "        print(y_hat)\n",
        "        print(t)\n",
        "        print('Loss: ', Loss)\n",
        "        \n",
        "    dy = (y_hat - t) / X.shape[0]\n",
        "    dz1, dW2, db2 = affine_layer_backward(dy, cache2)\n",
        "    da1 = sigmoid_grad(a1) * dz1\n",
        "    dX, dW1, db1 = affine_layer_backward(da1, cache1)\n",
        "    \n",
        "    W1, b1, W2, b2 = update_params(W1, b1, W2, b2, dW1, db1, dW2, db2, learning_rate)\n",
        "    \n",
        "    return W1, b1, W2, b2, Loss"
      ],
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PxP5Qz6yVOsh",
        "outputId": "03f94073-0d6e-48db-940f-b08f9e49cdfd"
      },
      "source": [
        "X = x_train_reshaped[:5]\n",
        "Y = y_train[:5]\n",
        "\n",
        "# train_step을 다섯 번 반복 돌립니다.\n",
        "for i in range(5):\n",
        "    W1, b1, W2, b2, _ = train_step(X, Y, W1, b1, W2, b2, learning_rate=0.1, verbose=True)"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "---------\n",
            "[[0.05674441 0.0632375  0.11896945 0.04881031 0.14482097 0.07886604\n",
            "  0.18482218 0.07281912 0.13743409 0.09347592]\n",
            " [0.05017012 0.07100013 0.17333714 0.05713078 0.12440563 0.09430148\n",
            "  0.14374441 0.07783597 0.13737567 0.07069867]\n",
            " [0.06154569 0.06490294 0.13456916 0.04853017 0.11732402 0.07731311\n",
            "  0.20132694 0.06764575 0.14167351 0.08516871]\n",
            " [0.05913787 0.0871464  0.14725887 0.05678236 0.13295048 0.07740272\n",
            "  0.16740829 0.06349355 0.12924453 0.07917493]\n",
            " [0.06337856 0.05909151 0.15955242 0.04002368 0.16309729 0.07974551\n",
            "  0.17667426 0.06448575 0.11364428 0.08030675]]\n",
            "[[0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
            " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]]\n",
            "Loss:  2.527444645825933\n",
            "---------\n",
            "[[0.07119715 0.07726486 0.10054724 0.04709718 0.15626968 0.09914544\n",
            "  0.14931886 0.06926857 0.11741446 0.11247656]\n",
            " [0.06736155 0.08516384 0.14685137 0.05507707 0.13555833 0.11427951\n",
            "  0.11755282 0.07445269 0.11807282 0.08563   ]\n",
            " [0.07510635 0.07733838 0.11668364 0.04724296 0.13356832 0.09128713\n",
            "  0.16789554 0.06431967 0.12443643 0.10212159]\n",
            " [0.07213929 0.11146263 0.12400147 0.05464016 0.14277743 0.09346915\n",
            "  0.13531687 0.05990224 0.11119778 0.09509297]\n",
            " [0.07950379 0.07189322 0.13338344 0.03857408 0.1777473  0.09668891\n",
            "  0.14228585 0.06104111 0.09740905 0.10147325]]\n",
            "[[0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
            " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]]\n",
            "Loss:  2.3008032961454203\n",
            "---------\n",
            "[[0.08485101 0.08978911 0.08540085 0.04425043 0.16157278 0.11820079\n",
            "  0.1230384  0.06433706 0.10027748 0.12828209]\n",
            " [0.08574198 0.09717163 0.12502306 0.05171823 0.14162351 0.13139214\n",
            "  0.09797901 0.06953272 0.10152225 0.09829546]\n",
            " [0.08765822 0.08823375 0.10150702 0.04494292 0.14631528 0.10296653\n",
            "  0.14236909 0.05991638 0.10917526 0.11691555]\n",
            " [0.08361076 0.13557872 0.10494941 0.05124498 0.14693295 0.10706814\n",
            "  0.11151223 0.05522528 0.09558993 0.10828761]\n",
            " [0.09442001 0.08309493 0.11212938 0.03617926 0.18523552 0.11094896\n",
            "  0.11695136 0.05638353 0.08344775 0.12120931]]\n",
            "[[0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
            " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]]\n",
            "Loss:  2.1244427912790735\n",
            "---------\n",
            "[[0.09740529 0.10067999 0.07313809 0.0409869  0.1629637  0.13570728\n",
            "  0.10309314 0.05904485 0.08609128 0.14088948]\n",
            " [0.10484556 0.10691623 0.10726418 0.04785977 0.14427846 0.14546309\n",
            "  0.08294753 0.06411291 0.08773733 0.10857494]\n",
            " [0.09896367 0.0975199  0.08889367 0.04222577 0.15664697 0.11238151\n",
            "  0.12247409 0.05524926 0.09617117 0.129474  ]\n",
            " [0.09333855 0.15904239 0.08958396 0.0474061  0.14748954 0.11810745\n",
            "  0.09342702 0.05033526 0.0825668  0.11870295]\n",
            " [0.10777675 0.09261405 0.09514843 0.03345195 0.18816273 0.1224828\n",
            "  0.09784201 0.05146516 0.07187898 0.13917715]]\n",
            "[[0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
            " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]]\n",
            "Loss:  1.9833749461899592\n",
            "---------\n",
            "[[0.10870156 0.10996749 0.06321995 0.03770389 0.1621217  0.15163118\n",
            "  0.08764811 0.0539138  0.07447452 0.1506178 ]\n",
            " [0.12429213 0.11450245 0.09281827 0.0439583  0.14484859 0.15667967\n",
            "  0.07116114 0.05875169 0.07635689 0.11663088]\n",
            " [0.1089071  0.10525357 0.07846256 0.03943318 0.16553532 0.11975875\n",
            "  0.10670714 0.05073557 0.08524744 0.13995938]\n",
            " [0.10128506 0.18163786 0.07720608 0.04356997 0.14601104 0.12678657\n",
            "  0.07941678 0.04566682 0.07183221 0.12658759]\n",
            " [0.1194191  0.10052374 0.08159246 0.0307256  0.18851281 0.1315443\n",
            "  0.08313691 0.04675684 0.06240764 0.15538062]]\n",
            "[[0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
            " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]]\n",
            "Loss:  1.867522676886809\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dDw3fFbOVXTP"
      },
      "source": [
        "def predict(W1, b1, W2, b2, X):\n",
        "    a1 = np.dot(X, W1) + b1\n",
        "    z1 = sigmoid(a1)\n",
        "    a2 = np.dot(z1, W2) + b2\n",
        "    y = softmax(a2)\n",
        "\n",
        "    return y"
      ],
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hnOSKJlAVYx3",
        "outputId": "045e8d4c-5e17-4803-aa1b-1fcbaf6631ef"
      },
      "source": [
        "# X = x_train[:100] 에 대해 모델 추론을 시도합니다. \n",
        "X = x_train_reshaped[:100]\n",
        "Y = y_test[:100]\n",
        "result = predict(W1, b1, W2, b2, X)\n",
        "result[0]"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.11867616, 0.11776495, 0.05515879, 0.03460011, 0.16014279,\n",
              "       0.16611097, 0.07548228, 0.04917855, 0.06497034, 0.15791506])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aI9kHBaaVa3I"
      },
      "source": [
        "def accuracy(W1, b1, W2, b2, x, y):\n",
        "    y_hat = predict(W1, b1, W2, b2, x)\n",
        "    y_hat = np.argmax(y_hat, axis=1)\n",
        "\n",
        "    accuracy = np.sum(y_hat == y) / float(x.shape[0])\n",
        "    return accuracy"
      ],
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vCdkQ7FMVbs3"
      },
      "source": [
        "def init_params(input_size, hidden_size, output_size, weight_init_std=0.01):\n",
        "\n",
        "    W1 = weight_init_std * np.random.randn(input_size, hidden_size)\n",
        "    b1 = np.zeros(hidden_size)\n",
        "    W2 = weight_init_std * np.random.randn(hidden_size, output_size)\n",
        "    b2 = np.zeros(output_size)\n",
        "\n",
        "    print(W1.shape)\n",
        "    print(b1.shape)\n",
        "    print(W2.shape)\n",
        "    print(b2.shape)\n",
        "    \n",
        "    return W1, b1, W2, b2"
      ],
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GpBAWmrlVhCn",
        "outputId": "f26e70da-060e-4770-9f5c-f5514d7e0c6a"
      },
      "source": [
        "# 하이퍼파라미터\n",
        "iters_num = 50000  # 반복 횟수를 적절히 설정한다.\n",
        "train_size = x_train.shape[0]\n",
        "batch_size = 100   # 미니배치 크기\n",
        "learning_rate = 0.1\n",
        "\n",
        "train_loss_list = []\n",
        "train_acc_list = []\n",
        "test_acc_list = []\n",
        "\n",
        "# 1에폭당 반복 수\n",
        "iter_per_epoch = max(train_size / batch_size, 1)\n",
        "\n",
        "W1, b1, W2, b2 = init_params(784, 50, 10)\n",
        "\n",
        "for i in range(iters_num):\n",
        "    # 미니배치 획득\n",
        "    batch_mask = np.random.choice(train_size, batch_size)\n",
        "    x_batch = x_train_reshaped[batch_mask]\n",
        "    y_batch = y_train[batch_mask]\n",
        "    \n",
        "    W1, b1, W2, b2, Loss = train_step(x_batch, y_batch, W1, b1, W2, b2, learning_rate=0.1, verbose=False)\n",
        "\n",
        "    # 학습 경과 기록\n",
        "    train_loss_list.append(Loss)\n",
        "    \n",
        "    # 1에폭당 정확도 계산\n",
        "    if i % iter_per_epoch == 0:\n",
        "        print('Loss: ', Loss)\n",
        "        train_acc = accuracy(W1, b1, W2, b2, x_train_reshaped, y_train)\n",
        "        test_acc = accuracy(W1, b1, W2, b2, x_test_reshaped, y_test)\n",
        "        train_acc_list.append(train_acc)\n",
        "        test_acc_list.append(test_acc)\n",
        "        print(\"train acc, test acc | \" + str(train_acc) + \", \" + str(test_acc))"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(784, 50)\n",
            "(50,)\n",
            "(50, 10)\n",
            "(10,)\n",
            "Loss:  2.307094783145644\n",
            "train acc, test acc | 0.13226666666666667, 0.1356\n",
            "Loss:  0.8580084171442388\n",
            "train acc, test acc | 0.7889833333333334, 0.7917\n",
            "Loss:  0.4880275479790022\n",
            "train acc, test acc | 0.8774833333333333, 0.8797\n",
            "Loss:  0.3597935152318209\n",
            "train acc, test acc | 0.8982166666666667, 0.9011\n",
            "Loss:  0.3788424517655971\n",
            "train acc, test acc | 0.9092166666666667, 0.9121\n",
            "Loss:  0.21826313953074583\n",
            "train acc, test acc | 0.91415, 0.9166\n",
            "Loss:  0.14813521918170264\n",
            "train acc, test acc | 0.9202, 0.9213\n",
            "Loss:  0.14480577046173596\n",
            "train acc, test acc | 0.9242666666666667, 0.9264\n",
            "Loss:  0.31416259567838606\n",
            "train acc, test acc | 0.9285666666666667, 0.9291\n",
            "Loss:  0.1868593485220598\n",
            "train acc, test acc | 0.9316, 0.9325\n",
            "Loss:  0.18966427826784263\n",
            "train acc, test acc | 0.9343666666666667, 0.9352\n",
            "Loss:  0.211039397963499\n",
            "train acc, test acc | 0.93685, 0.9364\n",
            "Loss:  0.13975238989540847\n",
            "train acc, test acc | 0.9394, 0.9382\n",
            "Loss:  0.09335227593815805\n",
            "train acc, test acc | 0.9417666666666666, 0.9396\n",
            "Loss:  0.17089598554342106\n",
            "train acc, test acc | 0.9434, 0.9423\n",
            "Loss:  0.1886884084778255\n",
            "train acc, test acc | 0.9450833333333334, 0.9445\n",
            "Loss:  0.13734714133854117\n",
            "train acc, test acc | 0.94645, 0.9448\n",
            "Loss:  0.12086081565668884\n",
            "train acc, test acc | 0.94845, 0.948\n",
            "Loss:  0.16196480488922468\n",
            "train acc, test acc | 0.9503333333333334, 0.9484\n",
            "Loss:  0.13789756573413606\n",
            "train acc, test acc | 0.9506166666666667, 0.9491\n",
            "Loss:  0.11619518194277974\n",
            "train acc, test acc | 0.9522666666666667, 0.9508\n",
            "Loss:  0.11587870619932863\n",
            "train acc, test acc | 0.9535166666666667, 0.9522\n",
            "Loss:  0.1724127909737286\n",
            "train acc, test acc | 0.9542833333333334, 0.9538\n",
            "Loss:  0.22078440248733802\n",
            "train acc, test acc | 0.9560333333333333, 0.9542\n",
            "Loss:  0.19102031035600786\n",
            "train acc, test acc | 0.9577333333333333, 0.9548\n",
            "Loss:  0.25858124512576697\n",
            "train acc, test acc | 0.9584666666666667, 0.9548\n",
            "Loss:  0.16812270314864597\n",
            "train acc, test acc | 0.9588666666666666, 0.9558\n",
            "Loss:  0.2142382313086599\n",
            "train acc, test acc | 0.9600333333333333, 0.9562\n",
            "Loss:  0.05809299931861139\n",
            "train acc, test acc | 0.9609333333333333, 0.9574\n",
            "Loss:  0.13564850117848895\n",
            "train acc, test acc | 0.9618833333333333, 0.9587\n",
            "Loss:  0.06534309053773889\n",
            "train acc, test acc | 0.9621166666666666, 0.9584\n",
            "Loss:  0.08455258263032077\n",
            "train acc, test acc | 0.96355, 0.9596\n",
            "Loss:  0.13646593905927243\n",
            "train acc, test acc | 0.9643833333333334, 0.9594\n",
            "Loss:  0.09928364749382496\n",
            "train acc, test acc | 0.9648333333333333, 0.961\n",
            "Loss:  0.11118914930866237\n",
            "train acc, test acc | 0.96595, 0.9614\n",
            "Loss:  0.09776580453674118\n",
            "train acc, test acc | 0.9663333333333334, 0.9621\n",
            "Loss:  0.11253759995621318\n",
            "train acc, test acc | 0.9669166666666666, 0.9621\n",
            "Loss:  0.0835887716271056\n",
            "train acc, test acc | 0.96735, 0.9616\n",
            "Loss:  0.19653179762674136\n",
            "train acc, test acc | 0.9684666666666667, 0.9629\n",
            "Loss:  0.16026740539649342\n",
            "train acc, test acc | 0.9691666666666666, 0.9632\n",
            "Loss:  0.11396274889573696\n",
            "train acc, test acc | 0.9694166666666667, 0.9633\n",
            "Loss:  0.18903969377690755\n",
            "train acc, test acc | 0.96995, 0.9638\n",
            "Loss:  0.10769460037197078\n",
            "train acc, test acc | 0.9705833333333334, 0.9642\n",
            "Loss:  0.09268988468922096\n",
            "train acc, test acc | 0.9708, 0.9637\n",
            "Loss:  0.19556344761988734\n",
            "train acc, test acc | 0.9710166666666666, 0.9644\n",
            "Loss:  0.13825451618819037\n",
            "train acc, test acc | 0.9713833333333334, 0.965\n",
            "Loss:  0.05130747816736848\n",
            "train acc, test acc | 0.9722833333333334, 0.965\n",
            "Loss:  0.055958511090320434\n",
            "train acc, test acc | 0.9723333333333334, 0.9658\n",
            "Loss:  0.13014113971450922\n",
            "train acc, test acc | 0.9731166666666666, 0.9655\n",
            "Loss:  0.09165370325810761\n",
            "train acc, test acc | 0.9734833333333334, 0.966\n",
            "Loss:  0.08695208847269127\n",
            "train acc, test acc | 0.97375, 0.9663\n",
            "Loss:  0.05463708925286304\n",
            "train acc, test acc | 0.9741833333333333, 0.9665\n",
            "Loss:  0.03919099043922147\n",
            "train acc, test acc | 0.9743833333333334, 0.9672\n",
            "Loss:  0.13725237888183173\n",
            "train acc, test acc | 0.97495, 0.9689\n",
            "Loss:  0.12118807579839784\n",
            "train acc, test acc | 0.9754, 0.9681\n",
            "Loss:  0.0886296739438364\n",
            "train acc, test acc | 0.9754333333333334, 0.9682\n",
            "Loss:  0.055628539531583\n",
            "train acc, test acc | 0.9761333333333333, 0.9673\n",
            "Loss:  0.053095494981683\n",
            "train acc, test acc | 0.9765166666666667, 0.9693\n",
            "Loss:  0.08617167802107899\n",
            "train acc, test acc | 0.9763833333333334, 0.9684\n",
            "Loss:  0.06505425398106918\n",
            "train acc, test acc | 0.9768, 0.9693\n",
            "Loss:  0.026999357290167003\n",
            "train acc, test acc | 0.9773333333333334, 0.968\n",
            "Loss:  0.06046500790945219\n",
            "train acc, test acc | 0.9775333333333334, 0.9682\n",
            "Loss:  0.06250248335313058\n",
            "train acc, test acc | 0.97785, 0.9677\n",
            "Loss:  0.04204160344560673\n",
            "train acc, test acc | 0.9783666666666667, 0.9695\n",
            "Loss:  0.062790497782025\n",
            "train acc, test acc | 0.9783166666666666, 0.9691\n",
            "Loss:  0.07639220362222468\n",
            "train acc, test acc | 0.9789166666666667, 0.9696\n",
            "Loss:  0.0883609425483885\n",
            "train acc, test acc | 0.9793666666666667, 0.9696\n",
            "Loss:  0.09599233946095953\n",
            "train acc, test acc | 0.9794333333333334, 0.9692\n",
            "Loss:  0.0585537400116361\n",
            "train acc, test acc | 0.98, 0.9698\n",
            "Loss:  0.06862039874912444\n",
            "train acc, test acc | 0.9798833333333333, 0.9698\n",
            "Loss:  0.12833802299770666\n",
            "train acc, test acc | 0.9801, 0.9701\n",
            "Loss:  0.1278856662352281\n",
            "train acc, test acc | 0.9806166666666667, 0.9699\n",
            "Loss:  0.07312643974237118\n",
            "train acc, test acc | 0.9806333333333334, 0.9704\n",
            "Loss:  0.07046553204128803\n",
            "train acc, test acc | 0.9807833333333333, 0.9702\n",
            "Loss:  0.02808250786334589\n",
            "train acc, test acc | 0.9809833333333333, 0.9703\n",
            "Loss:  0.06957825907750198\n",
            "train acc, test acc | 0.9814333333333334, 0.9699\n",
            "Loss:  0.0973274494484459\n",
            "train acc, test acc | 0.9816, 0.9709\n",
            "Loss:  0.04366405693838489\n",
            "train acc, test acc | 0.9815666666666667, 0.97\n",
            "Loss:  0.05990738701582035\n",
            "train acc, test acc | 0.9818333333333333, 0.9707\n",
            "Loss:  0.02860906899472901\n",
            "train acc, test acc | 0.9819666666666667, 0.9694\n",
            "Loss:  0.043904264456087104\n",
            "train acc, test acc | 0.9819333333333333, 0.9703\n",
            "Loss:  0.09146732904620254\n",
            "train acc, test acc | 0.9825166666666667, 0.9715\n",
            "Loss:  0.02591598904793018\n",
            "train acc, test acc | 0.98275, 0.9704\n",
            "Loss:  0.03134198670039741\n",
            "train acc, test acc | 0.9830833333333333, 0.9712\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 392
        },
        "id": "rd5COV53Vivk",
        "outputId": "f48a6bbf-b007-4316-a5a7-52c106995646"
      },
      "source": [
        "from matplotlib.pylab import rcParams\n",
        "rcParams['figure.figsize'] = 12, 6 \n",
        "\n",
        "# Accuracy 그래프 그리기\n",
        "markers = {'train': 'o', 'test': 's'}\n",
        "x = np.arange(len(train_acc_list))\n",
        "plt.plot(x, train_acc_list, label='train acc')\n",
        "plt.plot(x, test_acc_list, label='test acc', linestyle='--')\n",
        "plt.xlabel(\"epochs\")\n",
        "plt.ylabel(\"accuracy\")\n",
        "plt.ylim(0, 1.0)\n",
        "plt.legend(loc='lower right')\n",
        "plt.show()"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 864x432 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 392
        },
        "id": "PTI5a4jHVkYZ",
        "outputId": "b9851f6f-5442-4b6e-cf7a-b87cf56d7d9e"
      },
      "source": [
        "# Loss 그래프 그리기\n",
        "x = np.arange(len(train_loss_list))\n",
        "plt.plot(x, train_loss_list, label='train acc')\n",
        "plt.xlabel(\"epochs\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.ylim(0, 3.0)\n",
        "plt.legend(loc='best')\n",
        "plt.show()"
      ],
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 864x432 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}